\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{hyperref}

\setlength{\topmargin}{0pt}
\setlength{\textheight}{9in}
\setlength{\headheight}{0pt}
\setlength{\headsep}{0pt}
\setlength{\oddsidemargin}{0.25in}
\setlength{\textwidth}{6in}
\pagestyle{plain}

\begin{document}

\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\raisebox{0.6in}[0in]{\makebox[\textwidth][r]{\it
 Math}}
\vspace{-0.7in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
\bf\large IST718 Big Data Analysis
\end{center}

\noindent
Lecturer:                Prof. Daniel Acuna
\hfill
Lecture \#               1 \& 2
\\
Scribe:                  Lizhen Liang \& Yimin Xiao
\hfill
                         1/15/2019

\noindent
\rule{\textwidth}{1pt}

\medskip

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% body of scribe notes goes here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algebra}

\subsection{Scalar}
The representation of a single number  \newline\newline
i.e.\\
\begin{align*}
\alpha = 0.1\\
\beta = 0.5
\end{align*}

\subsection{Notation}
We let $\textbf X$ denote a $n \times p$ matrix whose $(i,j)$th element is $x_{ij}$. That is:  \newline

$$
\textbf X = \begin{bmatrix} x_{11}&x_{12}&\cdots&x_{1p}\\ x_{21}&x_{22}&\cdots&x_{2p}\\ 
\vdots&\vdots&\ddots&\vdots\\ x_{n1}&x_{n2}&\cdots&x_{np}\\ \end{bmatrix}
$$\newline

A matrix is an arrangement of scalars. You can think of it as a spreadsheet with $n$ rows and $p$\newline\newline

The rows of $\textbf X$ can be written as $x_1, x_2,...,x_n$. Here $x_i$ is a vector of length $p$, containing the $p$ variable measurements for the $i$th observation. That is,  
$$x_i = \begin{pmatrix} x_{i1}\\ x_{i2} \\ \vdots\\ x_{ip}\\ \end{pmatrix}$$\newline

IMPORTANT: vectors are by default represented as columns.\newline\newline

The columns of $\textbf X$ can written as $x_1, x_2,...,x_p$. Each is a vector of length $n$. That is,  \newline

$${\scriptsize \textbf X_j} = \begin{pmatrix} x_{1j}\\ x_{2j} \\ \vdots\\ x_{nj}\\ \end{pmatrix}$$ \newline\newline

Using the previous notation, the matrix $\textbf X$ can be written as  \newline

\begin{align*}
\textbf X = \begin{pmatrix} {\scriptsize \textbf X_1}&{\scriptsize \textbf X_2}&\cdots&{\scriptsize \textbf X_p}\\ \end{pmatrix}
\quad or \quad
\textbf X = \begin{pmatrix} x_1^T\\ x_2^T \\ \vdots\\ x_n^T\\ \end{pmatrix}
\end{align*}

\subsubsection{Transpose}

The $\;^T\;$ notation denotes the \textbf{transpose} of a matrix or vector. So, for example,

$$\textbf X^T = \begin{bmatrix} x_{11}&x_{21}&\cdots&x_{n1}\\ x_{12}&x_{22}&\cdots&x_{n2}\\ 
\vdots&\vdots&\ddots&\vdots\\ x_{1p}&x_{2p}&\cdots&x_{np}\\ \end{bmatrix}$$\newline

\centering while  

$$x_i^T = \begin{pmatrix} x_{i1}&x_{i2}&\cdots&x_{ip}\\ \end{pmatrix}$$

We use $y_i$ to denote the $i$th observation of the variable on wish we wish to make predictions. Hence we write the set of all $n$ observations in *vector form* as  

$$\textbf y = \begin{pmatrix} y_1\\ y_2 \\ \vdots\\ y_n\\ \end{pmatrix}$$

Then our observed data consist of $\{(x_1,y_1), (x_2,y_2),...,(x_n,y_n)\}$, where each $x_i$ is a vector of length $p$.
If $p=1$, then $x_i$ is simply a scalar.

We use $y_i$ to denote the $i$th observation of the variable on wish we wish to make predictions. Hence we write the set of all $n$ observations in *vector form* as  

$$\textbf y = \begin{pmatrix} y_1\\ y_2 \\ \vdots\\ y_n\\ \end{pmatrix}$$

Then our observed data consist of $\{(x_1,y_1), (x_2,y_2),...,(x_n,y_n)\}$, where each $x_i$ is a vector of length $p$.
If $p=1$, then $x_i$ is simply a scalar.\newline 

\begin{flushleft}
\subsection{Matrix}
We can define a matrix by its components as follows
$\textbf A=(f(i,j))_{ij}$where $f(i, j)$ is a function of $i$ and $j$.\newline 

\textbf{For example}, define the matrix 

$$
\textbf X = 
\begin{bmatrix} 
1 & 1 & \cdots & 1\\ 
0 & 1 & \cdots & 1\\ 
\vdots&\vdots&\ddots&\vdots\\ 0& 0 & \cdots & 1\\ 
\end{bmatrix}
$$

using a function: \newline
\begin{align*}
    f(i, j) = 1 \quad when\quad j >= i \\
    otherwise,\quad f(i, j)=0
\end{align*}
\end{flushleft}

\begin{flushleft}
\subsubsection{Matrix operations}
Scalar times matrix: $\alpha \textbf A=(\alpha \times a_{ij} )_{ij}$\newline
Matrix addition: $\textbf A + \textbf B $ (add each element one at a time)\newline
Matrix multiplication: $\textbf A \textbf B$ ($\text{cols}_A = \text{rows}_B$)
$$\textbf A \textbf B=\left(\sum_{z} a_{iz} b_{zj}\right)_{ij}$$
Matrix transposition: make rows the columns
$$\textbf{A}^T=(a_{ij} )_{ji}$$
Many operations can be easily written as matrices\newline

\subsubsection{Special Matrix Properties}
Identity matrix (diagonal values are 1, everything else is 0)\newline
\begin{align*}
    I = \begin{bmatrix} 1&\cdots&0\\ \vdots&\ddots&\vdots\\ 0&\cdots&1\\ \end{bmatrix}
\end{align*}

Matrix inverse: $AA^{−1}=I$ \newline
Matrix addition is commutative: $A + B = B + A$ \newline
Matrix multiplication is NOT commutative: $AB \neq BA$
$(AB)^T=B^T A^T$
\newline
\subsubsection{Dimension}
To indicate that an object is: \newline
\begin{itemize}
    \item[-] a scalar, we will use the notation $a \in \mathbb{R}$  
    \item[-] a vector of length $n$, we will use $\textbf a \in \mathbb{R^n}$ 
    \item[-] a vector of length $k$, we will use $a \in \mathbb{R^k}$ 
    \item[-] a $r \times s$ matrix, we will use $\textbf A \in \mathbb{R}^{r \times s}$ 
\end{itemize}

\subsection{Application}
Model 1: \newline
\begin{itemize}
  \item[-] $\widehat{income}=f(age)= 20000+5000 \times age$
  \item[-] The unit of the intercept is different from the unit of the slope
  \item[-] Using matrix notation to make predictions for $age = \{20, 25, 40\}$
  \item[-] Represent model as a vector $b = \begin{pmatrix} 20000\\ 5000\\ \end{pmatrix}$
  \item[-] Represent data as matrix $X$
  \item[-] Making predictions: $X \times b$
\end{itemize}

\subsection{Optimization}
Define the loss as a function of the model's parameters and we try to minize it:
$$
\widehat{\Theta} = \arg \min_\Theta L(\Theta)
$$\newline
We can find a minimum or maximum of a function by looking at the slope \newline
Finding the minimum of a function:
$$
\frac{df(x)}{dx}=0
$$

In multiple dimensions it is called a gradient:
$$
g = {\begin{pmatrix} \frac{df(x_1)}{dx_1} \frac{df(x_2)}{dx_2} \cdots \frac{df(x_p)}{dx_p}\\ \end{pmatrix}}^T
$$

\subsubsection{Derivatives}
Definition of the derivative:
$$
\frac{df(x)}{d(x)} \approx \lim\limits_{\Delta x \to 0} {\frac {f(x+\Delta x)-f(x)}{\Delta x}}
$$
Which means that the infinitesimal change in the function as the change is taken to zero
$$i.e.$$
  $$f_1(x) = a + xb$$
  $$f_2(x) = x^2$$

\subsubsection*{Common derivation rules}
Chain rule:
$$
{\textstyle \frac{dg(f(x)}{dx}= \frac{dg(f)}{f}\frac{df(x)}{x}}
$$

\leftline{Other rules:}
\centering
$\frac{d(cf(x))}{dx}= c\frac{df(x)}{dx}$   \\
\quad \\ \quad\quad
$\frac{d(f(x)+g(x))}{dx}=\frac{d(f(x))}{dx}+\frac{g(g(x))}{dx}$ \\
\quad \\
\quad\quad\quad\quad\quad\quad\quad\quad\quad
$\frac{d(x^n)}{dx}=nx^{n-1}$ 
\newline

\leftline{Common properties:}
${\displaystyle \frac{d(e^x)}{dx}= e^x}$ \\
${\displaystyle \frac{d(\log(x))}{dx}=\frac{1}{x}}$ \\
\end{flushleft}

\begin{flushleft}
\subsection{Loss Function}
\leftline{A common prediction function for probability values is the sigmoid:}
\quad \\
$$\sigma(z)=\frac{1}{1+e^{−z}}$$

\leftline{Logistic regression has a loss function called \textbf{cross-entropy}:}
$$l(z) = -y\log(\sigma(z)) - (1−y)\log⁡(1−\sigma(z))$$

\end{flushleft}

\begin{flushleft}
\section{Probability}
\subsection{Set}
The collection of all possible outcomes in an experiment is called \textbf{sample space} \newline
\quad \newline
\textbf{For example:} \newline
The sample space of any possible outcome for rolling a dice: \newline
$$
    S = \{1, 2, 3, 4, 5, 6\}
$$

The sample space of any possible outcome for flipping a coin: \newline
$$
    S = \{head, tail\}
$$
\subsection{Probability}
Any function that follows the following axioms is a \textbf{probability distribution} \newline
\quad \newline
1. Probability of any event is greater or equal to zero \newline
\quad
$$p(A) \geq 0$$
2. If an event $S$ is certain to occur, then:   
$$p(S) = 1$$
3. The probability of an infinite number of independent events $A, B, C,\ldots$ is the sum of the probability of each event:  
$$p(A) + p(B) + p(C) + \ldots$$  
\subsubsection{Properties}
For event $A$,  \newline
\quad
$$p(\lnot{A}) = 1 - p(A)$$ \\ 
For any two events $A$ and $B$,  \newline
\quad 
$$p(A \cup B) = p(A) + p(B) - p(A \cap B)$$  

Conditional probability (probability of an event knowing that another event is certain)  \newline
\quad 
$$p(A \mid B) = P(A \cap B) / P(B)$$
\quad \newline
\textbf{Example:}\href{https://www.montyhallproblem.com/}{The Monty Hall Problem}

\subsection{Distribution}
We only need to deal with two kinds of distributions:
\begin{itemize}
    \item [-] Discrete distribution
    \item [-] Continues distribution 
\end{itemize}
\textbf{Real variable}: A random variable is a real-valued function that is defined on a sample space of an experiment. The distribution of a random variable is the probability of the events underlying the random variable. \newline
\quad \newline
\textbf{Support set}: a set of conditions or restrains of $x$ that makes $p(x) > 0$ \newline
\quad \newline
\textbf{discrete random variable}: the random variable $X$ can take on a finite number of $k$ different values $x_1, ... x_k$ or, an infinite sequence of them. \newline
\quad \newline 
\textbf{discrete probability distribution}: Describes the probability of each real value $x$ of a discrete random variable: $$ p(X = x)$$sometimes denoted simply as $p(x)$.\\ The sum of all events must sum up to 1:\\ \quad  $$\sum_x p(x) = 1$$ 
$p$ is also call a \textbf{probability mass function}

\quad \newline 
\textbf{continuous random variables}: Random variables that can take on every value on a bounded closed intervals $[a,b]$:
$$p(a \leq X \leq b) = \int_a^b p(x) dx$$
with properties: \newline
\begin{itemize}
    \item[-] $p(x) \geq 0$ for all $x$
    \item[-] $\int_{-\infty}^{\infty}p(x) = 1$
    \item[-] A single point in a continuous distribution has probability 0
    \item[-] $p$ is called a \textbf{probability density function}
\end{itemize}

\section{Common Statistics}
\textbf{Expectation}: A fancy way to express \textbf{average}
$$E[f(x)] = \sum_x p(x) f(x) \quad E[f(x)] = \int_x p(x) f(x) dx $$
\textbf{Variance}: The property describing how the data spread around the average of the data set:
$$Var[f(x)] = E[ (f(x) - E[f(x)])^2 ]$$
\textbf{Covariance}: Co-spread of two data set:
$$Cov(f(x), g(y)) = E[(f(x) - E[f(x)])(g(y) - E[g(y)])]$$
\textbf{joint-distributions}: The joint distribution of a set of random variables
$$p(X_1 \in C_1, X_2 \in C_2, \dots, X_k \in C_k)$$
can be read as the probability that the random variables are simultaneously in the intervals $C_1, \dots, C_k$\\
\quad \\
\textbf{Marginal probability}: \\ \quad \\
From a simple example distribution 
$$p(X_1 \in C_1, X_2 \in C_2)$$
we can obtain the following 
$$p(X_1 \in C_1) = \sum_{x_2 \in C_2} p(X_1 = x_1, X_2 = x_2)$$
for a discrete distribution, and
$$p(X_1 \in C_1) = \int_{x_2 \in C_2} p(X_1 = x_1, X_2 = x_2) dx_2$$
for a continous distribution.\\
This can be generalized for many variables.

\textbf{Conditional probability}:
$$p(X_1 \in C_1 \mid X_2 \in C_2) = \frac{p(X_1 \in C_1 , X_2 \in C_2)}{p(X_2 \in C_2)} $$

\textbf{Independence}:If two random events are independent (they don't depend on each other), their joint probability can be expressed as the factor of their distributions:
$$p(X_1 \in C_1,  X_2 \in C_2) = p(X_1 \in C_1) p(X_2 \in C_2)$$

\end{flushleft}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
